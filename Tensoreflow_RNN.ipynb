{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t09eeeR5prIJ"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GCCk8_dHpuNf"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovpZyIhNIgoq"
      },
      "source": [
        "# Text generation with an RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcD2nPQvPOFM"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/text/tutorials/text_generation\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/text/docs/tutorials/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwpJ5IffzRG6"
      },
      "source": [
        "This tutorial demonstrates how to generate text using a character-based RNN. You will work with a dataset of Shakespeare's writing from Andrej Karpathy's [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). Given a sequence of characters from this data (\"Shakespear\"), train a model to predict the next character in the sequence (\"e\"). Longer sequences of text can be generated by calling the model repeatedly.\n",
        "\n",
        "Note: Enable GPU acceleration to execute this notebook faster. In Colab: *Runtime > Change runtime type > Hardware accelerator > GPU*.\n",
        "\n",
        "This tutorial includes runnable code implemented using [tf.keras](https://www.tensorflow.org/guide/keras/sequential_model) and [eager execution](https://www.tensorflow.org/guide/eager). The following is the sample output when the model in this tutorial trained for 30 epochs, and started with the prompt \"Q\":"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcygKkEVZBaa"
      },
      "source": [
        "<pre>\n",
        "QUEENE:\n",
        "I had thought thou hadst a Roman; for the oracle,\n",
        "Thus by All bids the man against the word,\n",
        "Which are so weak of care, by old care done;\n",
        "Your children were in your holy love,\n",
        "And the precipitation through the bleeding throne.\n",
        "\n",
        "BISHOP OF ELY:\n",
        "Marry, and will, my lord, to weep in such a one were prettiest;\n",
        "Yet now I was adopted heir\n",
        "Of the world's lamentable day,\n",
        "To watch the next way with his father with his face?\n",
        "\n",
        "ESCALUS:\n",
        "The cause why then we are all resolved more sons.\n",
        "\n",
        "VOLUMNIA:\n",
        "O, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, it is no sin it should be dead,\n",
        "And love and pale as any will to that word.\n",
        "\n",
        "QUEEN ELIZABETH:\n",
        "But how long have I heard the soul for this world,\n",
        "And show his hands of life be proved to stand.\n",
        "\n",
        "PETRUCHIO:\n",
        "I say he look'd on, if I must be content\n",
        "To stay him from the fatal of our country's bliss.\n",
        "His lordship pluck'd from this sentence then for prey,\n",
        "And then let us twain, being the moon,\n",
        "were she such a case as fills m\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bGsCP9DZFQ5"
      },
      "source": [
        "While some of the sentences are grammatical, most do not make sense. The model has not learned the meaning of words, but consider:\n",
        "\n",
        "* The model is character-based. When training started, the model did not know how to spell an English word, or that words were even a unit of text.\n",
        "\n",
        "* The structure of the output resembles a playâ€”blocks of text generally begin with a speaker name, in all capital letters similar to the dataset.\n",
        "\n",
        "* As demonstrated below, the model is trained on small batches of text (100 characters each), and is still able to generate a longer sequence of text with coherent structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srXC6pLGLwS6"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyKZj3bzf9p"
      },
      "source": [
        "### Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aavnuByVymwK",
        "outputId": "64031a7e-1d3d-429a-e734-57d4c683b0cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 76787 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(\"/content/hello.txt\", 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Duhg9NrUymwO",
        "outputId": "5ff48ee0-ca29-4575-b75b-afdc4cc6087c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3552445525303532555052431030435433250402122140311414051223221454124334311053025004333154510052055523101230142525553414352000030445122250221103443144025351125405433010540455334255303405102344310220342002431524234344133453531004435224411033430510443013\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IlCgQBRVymwR",
        "outputId": "1cc0789a-f705-45ab-f92c-f90df6430b7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a86OoYtO01go",
        "outputId": "5db49dff-087e-4fa7-efee-02a432427604",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>\n"
          ]
        }
      ],
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "print(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6GMlCe3qzaL9"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WLv5Q_2TC2pc",
        "outputId": "a503b3e5-aa47-48c3-88ef-32949882e6cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0]]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Wd2m3mqkDjRj"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c2GCh0ySD44s",
        "outputId": "abdfb6f1-a282-4bdc-b6c0-614506476081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'[UNK]', b'[UNK]', b'[UNK]', b'[UNK]', b'[UNK]', b'[UNK]', b'[UNK]'],\n",
              " [b'[UNK]', b'[UNK]', b'[UNK]']]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zxYI-PeltqKP",
        "outputId": "caefccfa-99f3-4c60-bf4b-f2d583b97402",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'[UNK][UNK][UNK][UNK][UNK][UNK][UNK]', b'[UNK][UNK][UNK]'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "w5apvBDn9Ind"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UopbsKi88tm5",
        "outputId": "4975b924-3630-4309-e919-9dd42302c64a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(76787,), dtype=int64, numpy=array([4, 6, 6, ..., 2, 5, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qmxrYDCTy-eL"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cjH5v45-yqqH",
        "outputId": "7d71646b-f428-4ee9-dc59-8a3e0321d59e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "5\n",
            "5\n",
            "2\n",
            "4\n",
            "4\n",
            "5\n",
            "5\n",
            "2\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "C-G2oaTxy6km"
      },
      "outputs": [],
      "source": [
        "seq_length = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZSYAcQV8OGP"
      },
      "source": [
        "The `batch` method lets you easily convert these individual characters to sequences of the desired size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BpdjRO2CzOfZ",
        "outputId": "78d5158c-6a9b-4bd6-dbb5-c1526c3eb763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'3' b'5' b'5' b'2' b'4' b'4' b'5' b'5' b'2' b'5' b'3'], shape=(11,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PHW902-4oZt"
      },
      "source": [
        "It's easier to see what this is doing if you join the tokens back into strings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QO32cMWu4a06",
        "outputId": "ece5ceae-beac-48d2-9315-a64ec9a40f5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'35524455253'\n",
            "b'03532555052'\n",
            "b'43103043543'\n",
            "b'32504021221'\n",
            "b'40311414051'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "B9iKPXkw5xwa"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GNbw-iR0ymwj",
        "outputId": "c1f8b65f-3575-4406-c43f-10ed3a8fe744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'3552445525'\n",
            "Target: b'5524455253'\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "p2pGotuNzf-S",
        "outputId": "33460c21-d1fc-49ca-c79e-f659ae7cab32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(65, 10), dtype=tf.int64, name=None), TensorSpec(shape=(65, 10), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 65\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wj8HQ2w8z4iO"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IX58Xj9z47Aw"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "C-_70kKAPrPU",
        "outputId": "485a3321-2435-45d8-e99a-7ff4213288e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(65, 10, 7) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vPGmAAXmVLGC",
        "outputId": "b513e87c-ed0f-4eb7-d474-c948f924442b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  1792      \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  7175      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,947,271\n",
            "Trainable params: 3,947,271\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "YqFMUQc_UFgM",
        "outputId": "ba7ba4fa-80cc-4979-ee35-95f8341134c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 6, 0, 1, 6, 3, 6, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xWcFwPwLSo05",
        "outputId": "63ebdf03-d0ac-4c08-fde0-b1bea8a5cdd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'4040052503'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'55[UNK]0525123'\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZOeWdgxNFDXq"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4HrXTACTdzY-",
        "outputId": "165580dc-09db-4329-f202-a5e0784a2e72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (65, 10, 7)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(1.9465061, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "MAJfS5YoFiHf",
        "outputId": "e058f7ca-5cf6-4d4d-a942-484fcb7cbd30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.0041738"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "DDl1_Een6rL0"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "W6fWTriUZP-n"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = '/content/training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_callback = ModelCheckpoint('model_weights.h5', save_weights_only=True)\n",
        "csv_logger = CSVLogger('training_log.csv', append=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "7yGBE2zxMMHs"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "UK-hmKjYVoll",
        "outputId": "66aa748b-df7d-4541-dde9-e16748c6e17a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "107/107 [==============================] - 5s 11ms/step - loss: 1.8094 - accuracy: 0.1667\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7961 - accuracy: 0.1664\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7947 - accuracy: 0.1681\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 2s 10ms/step - loss: 1.7935 - accuracy: 0.1673\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7935 - accuracy: 0.1686\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7931 - accuracy: 0.1697\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7931 - accuracy: 0.1704\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7929 - accuracy: 0.1688\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7926 - accuracy: 0.1727\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7926 - accuracy: 0.1701\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7921 - accuracy: 0.1718\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7926 - accuracy: 0.1690\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7923 - accuracy: 0.1720\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7925 - accuracy: 0.1693\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7921 - accuracy: 0.1724\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7923 - accuracy: 0.1727\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 2s 11ms/step - loss: 1.7921 - accuracy: 0.1708\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7921 - accuracy: 0.1719\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7921 - accuracy: 0.1732\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7921 - accuracy: 0.1696\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7915 - accuracy: 0.1736\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7916 - accuracy: 0.1733\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7919 - accuracy: 0.1724\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7914 - accuracy: 0.1744\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7917 - accuracy: 0.1742\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.7916 - accuracy: 0.1750\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.7915 - accuracy: 0.1755\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7912 - accuracy: 0.1760\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.7911 - accuracy: 0.1768\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.7909 - accuracy: 0.1789\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7906 - accuracy: 0.1791\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.7907 - accuracy: 0.1790\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.7904 - accuracy: 0.1816\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7898 - accuracy: 0.1816\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7891 - accuracy: 0.1831\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.7883 - accuracy: 0.1852\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.7865 - accuracy: 0.1875\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 2s 10ms/step - loss: 1.7853 - accuracy: 0.1908\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.7820 - accuracy: 0.1976\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.7777 - accuracy: 0.2016\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7697 - accuracy: 0.2152\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.7558 - accuracy: 0.2255\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.7309 - accuracy: 0.2447\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.6848 - accuracy: 0.2788\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.6071 - accuracy: 0.3223\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 2s 10ms/step - loss: 1.4934 - accuracy: 0.3805\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.3574 - accuracy: 0.4443\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.2291 - accuracy: 0.4986\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 1.1233 - accuracy: 0.5428\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 1.0381 - accuracy: 0.5754\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.9777 - accuracy: 0.5965\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 2s 12ms/step - loss: 0.9324 - accuracy: 0.6126\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 2s 10ms/step - loss: 0.9017 - accuracy: 0.6222\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.8794 - accuracy: 0.6284\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.8624 - accuracy: 0.6328\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.8467 - accuracy: 0.6369\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.8378 - accuracy: 0.6361\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.8284 - accuracy: 0.6393\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.8216 - accuracy: 0.6399\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 2s 11ms/step - loss: 0.8161 - accuracy: 0.6411\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.8108 - accuracy: 0.6416\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.8082 - accuracy: 0.6419\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.8030 - accuracy: 0.6407\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.8004 - accuracy: 0.6404\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7987 - accuracy: 0.6413\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7955 - accuracy: 0.6414\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7920 - accuracy: 0.6414\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 2s 10ms/step - loss: 0.7926 - accuracy: 0.6416\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7890 - accuracy: 0.6419\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7871 - accuracy: 0.6421\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7858 - accuracy: 0.6422\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7856 - accuracy: 0.6402\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7838 - accuracy: 0.6391\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7818 - accuracy: 0.6426\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7813 - accuracy: 0.6420\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 2s 10ms/step - loss: 0.7796 - accuracy: 0.6415\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7785 - accuracy: 0.6425\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.7776 - accuracy: 0.6429\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7769 - accuracy: 0.6427\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7762 - accuracy: 0.6403\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.7752 - accuracy: 0.6428\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7741 - accuracy: 0.6426\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 2s 10ms/step - loss: 0.7730 - accuracy: 0.6417\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.7725 - accuracy: 0.6414\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.7727 - accuracy: 0.6415\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7719 - accuracy: 0.6409\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.7705 - accuracy: 0.6436\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.7698 - accuracy: 0.6428\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 2s 11ms/step - loss: 0.7690 - accuracy: 0.6423\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7684 - accuracy: 0.6432\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.7680 - accuracy: 0.6425\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.7667 - accuracy: 0.6429\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7680 - accuracy: 0.6433\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.7660 - accuracy: 0.6432\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.7662 - accuracy: 0.6416\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.7659 - accuracy: 0.6444\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 1s 11ms/step - loss: 0.7648 - accuracy: 0.6437\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 2s 10ms/step - loss: 0.7642 - accuracy: 0.6434\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7644 - accuracy: 0.6441\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.7639 - accuracy: 0.6426\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback, csv_logger])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ybCXaeyZre8j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "text_generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}